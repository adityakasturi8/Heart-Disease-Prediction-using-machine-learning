{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c75f7e0",
   "metadata": {},
   "source": [
    "# Course: Health Care Analytics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5b3ca",
   "metadata": {},
   "source": [
    "# Author : Aditya Kasturi \n",
    "\n",
    "<b> Homework# - I </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf72f67",
   "metadata": {},
   "source": [
    "<b>Abstract :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa3914",
   "metadata": {},
   "source": [
    "There are 76 attributes in the Heart Disease Data Set, however only 14 of them are used in all published trials. To yet, the Cleveland database has been the only one that ML researchers have utilized to conduct their studies. The presence of heart illness in the patient is indicated by the \"target\" field. It has an integer value ranging from 0 (no presence) to 4, with 0 being the default. Most of the Cleveland database experiments have been focused on attempting to distinguish between presence (values 1, 2, 3, 4) and absence (values 0). (values 0). (In this case, the value is 0). Therefore, this assignment can be described as a problem of binary classification, as shown in the diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb7554",
   "metadata": {},
   "source": [
    "<b> Dataset : </b>\n",
    "https://archive.ics.uci.edu/ml/datasets/Heart+Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836c860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99894d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed.cleveland.data\", header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1b26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_question_mark(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].replace('?', np.nan)\n",
    "\n",
    "replace_question_mark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e41e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming The Columns\n",
    "df.columns = ['age', 'sex','cp','trestbps','chol','fbs', 'restecg', 'thalach', 'exang', 'oldpeak' , 'slope', 'ca','thal','heart_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81808c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['heart_failure'] =np.where(df['heart_failure'] >0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b78bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling the categorical columns\n",
    "df.sex = df.sex.astype('category')\n",
    "df.cp = df.cp.astype('category')\n",
    "df.fbs = df.fbs.astype('category')\n",
    "df.restecg = df.restecg.astype('category')\n",
    "df.slope = df.slope.astype('category')\n",
    "df.exang = df.exang.astype('category')\n",
    "df.thal = df.thal.astype('category')\n",
    "df.heart_failure = df.heart_failure.astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56d4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling the numerical column\n",
    "df.age = df.age.astype('float64')\n",
    "df.trestbps = df.trestbps.astype('float64')\n",
    "df.thalach = df.thalach.astype('float64')\n",
    "df.oldpeak = df.oldpeak.astype('float64')\n",
    "df.ca = df.ca.astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb95590",
   "metadata": {},
   "source": [
    "Displaying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a52c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak slope  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0     2.0    150.0   0.0      2.3   3.0   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0     2.0    108.0   1.0      1.5   2.0   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0     2.0    129.0   1.0      2.6   2.0   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0     0.0    187.0   0.0      3.5   3.0   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0     2.0    172.0   0.0      1.4   1.0   \n",
       "\n",
       "    ca thal heart_failure  \n",
       "0  0.0  6.0             0  \n",
       "1  3.0  3.0             1  \n",
       "2  2.0  7.0             1  \n",
       "3  0.0  3.0             0  \n",
       "4  0.0  3.0             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bcbd4e",
   "metadata": {},
   "source": [
    "Describing data in terms of numerical features in order to determine different statistical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb09ce4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>0.672241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.937438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age    trestbps        chol     thalach     oldpeak          ca\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000\n",
       "mean    54.438944  131.689769  246.693069  149.607261    1.039604    0.672241\n",
       "std      9.038662   17.599748   51.776918   22.875003    1.161075    0.937438\n",
       "min     29.000000   94.000000  126.000000   71.000000    0.000000    0.000000\n",
       "25%     48.000000  120.000000  211.000000  133.500000    0.000000    0.000000\n",
       "50%     56.000000  130.000000  241.000000  153.000000    0.800000    0.000000\n",
       "75%     61.000000  140.000000  275.000000  166.000000    1.600000    1.000000\n",
       "max     77.000000  200.000000  564.000000  202.000000    6.200000    3.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8227e",
   "metadata": {},
   "source": [
    "<b> TASK 1 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674830b",
   "metadata": {},
   "source": [
    "Checking the data for missing values and removing the rows which includes the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff0bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n",
      "(297, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c086a",
   "metadata": {},
   "source": [
    "<b> TASK 2 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878fa715",
   "metadata": {},
   "source": [
    "* Split the data inro feature vector and raget vector \n",
    "* Standardize all feature columns to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a136db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, df.columns == 'heart_failure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea84198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X[X.columns] = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26129a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936181</td>\n",
       "      <td>0.691095</td>\n",
       "      <td>-2.240629</td>\n",
       "      <td>0.750380</td>\n",
       "      <td>-0.276443</td>\n",
       "      <td>2.430427</td>\n",
       "      <td>1.010199</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>-0.696419</td>\n",
       "      <td>1.068965</td>\n",
       "      <td>2.264145</td>\n",
       "      <td>-0.721976</td>\n",
       "      <td>0.655877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.378929</td>\n",
       "      <td>0.691095</td>\n",
       "      <td>0.873880</td>\n",
       "      <td>1.596266</td>\n",
       "      <td>0.744555</td>\n",
       "      <td>-0.411450</td>\n",
       "      <td>1.010199</td>\n",
       "      <td>-1.816334</td>\n",
       "      <td>1.435916</td>\n",
       "      <td>0.381773</td>\n",
       "      <td>0.643781</td>\n",
       "      <td>2.478425</td>\n",
       "      <td>-0.894220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.378929</td>\n",
       "      <td>0.691095</td>\n",
       "      <td>0.873880</td>\n",
       "      <td>-0.659431</td>\n",
       "      <td>-0.353500</td>\n",
       "      <td>-0.411450</td>\n",
       "      <td>1.010199</td>\n",
       "      <td>-0.899420</td>\n",
       "      <td>1.435916</td>\n",
       "      <td>1.326662</td>\n",
       "      <td>0.643781</td>\n",
       "      <td>1.411625</td>\n",
       "      <td>1.172577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.941680</td>\n",
       "      <td>0.691095</td>\n",
       "      <td>-0.164289</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>-0.411450</td>\n",
       "      <td>-1.003419</td>\n",
       "      <td>1.633010</td>\n",
       "      <td>-0.696419</td>\n",
       "      <td>2.099753</td>\n",
       "      <td>2.264145</td>\n",
       "      <td>-0.721976</td>\n",
       "      <td>-0.894220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.498933</td>\n",
       "      <td>-1.446980</td>\n",
       "      <td>-1.202459</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>-0.835103</td>\n",
       "      <td>-0.411450</td>\n",
       "      <td>1.010199</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>-0.696419</td>\n",
       "      <td>0.295874</td>\n",
       "      <td>-0.976583</td>\n",
       "      <td>-0.721976</td>\n",
       "      <td>-0.894220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "0  0.936181  0.691095 -2.240629  0.750380 -0.276443  2.430427  1.010199   \n",
       "1  1.378929  0.691095  0.873880  1.596266  0.744555 -0.411450  1.010199   \n",
       "2  1.378929  0.691095  0.873880 -0.659431 -0.353500 -0.411450  1.010199   \n",
       "3 -1.941680  0.691095 -0.164289 -0.095506  0.051047 -0.411450 -1.003419   \n",
       "4 -1.498933 -1.446980 -1.202459 -0.095506 -0.835103 -0.411450  1.010199   \n",
       "\n",
       "    thalach     exang   oldpeak     slope        ca      thal  \n",
       "0  0.017494 -0.696419  1.068965  2.264145 -0.721976  0.655877  \n",
       "1 -1.816334  1.435916  0.381773  0.643781  2.478425 -0.894220  \n",
       "2 -0.899420  1.435916  1.326662  0.643781  1.411625  1.172577  \n",
       "3  1.633010 -0.696419  2.099753  2.264145 -0.721976 -0.894220  \n",
       "4  0.978071 -0.696419  0.295874 -0.976583 -0.721976 -0.894220  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50901e0e",
   "metadata": {},
   "source": [
    "<b> TASK 3 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc693c9",
   "metadata": {},
   "source": [
    "* Logistic Regression Model with 10 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67055c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******LOGISTIC REGRESSION*************\n",
      "Accuracy: 0.8316091954022988\n",
      "Sensitivity: 0.7940520590520591\n",
      "Specificity: 0.8628227431323406\n",
      "G-mean: 0.8221853737481325\n",
      "F1 Score: 0.8107249109002265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, roc_curve, auc, f1_score, roc_auc_score\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "accuracy = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "gmean = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    specificity.append(confusion_matrix(y_test, y_pred)[0,0]/(confusion_matrix(y_test, y_pred)[0,0] + confusion_matrix(y_test, y_pred)[0,1]))\n",
    "    gmean.append(np.sqrt(recall_score(y_test, y_pred) * specificity[-1]))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "    \n",
    "print('******LOGISTIC REGRESSION*************')    \n",
    "print('Accuracy:', np.mean(accuracy))\n",
    "print('Sensitivity:', np.mean(sensitivity))\n",
    "print('Specificity:', np.mean(specificity))\n",
    "print('G-mean:', np.mean(gmean))\n",
    "print('F1 Score:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e6804",
   "metadata": {},
   "source": [
    "* SVm Model with 10 folds cross validation along with Grid Search CV for best hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da45e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******SVM********\n",
      "Accuracy: 0.824367816091954\n",
      "Sensitivity: 0.7570668220668221\n",
      "Specificity: 0.8829762519042704\n",
      "G-mean: 0.8114259773255565\n",
      "F1 Score: 0.7937034594590816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "accuracy = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "gmean = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = SVC()\n",
    "    parameters = {'kernel': ['linear', 'rbf'], 'C': [1, 10]}\n",
    "    clf = GridSearchCV(model, parameters, cv=10)\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    specificity.append(confusion_matrix(y_test, y_pred)[0,0]/(confusion_matrix(y_test, y_pred)[0,0] + confusion_matrix(y_test, y_pred)[0,1]))\n",
    "    gmean.append(np.sqrt(recall_score(y_test, y_pred) * specificity[-1]))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "print('*******SVM********')\n",
    "print('Accuracy:', np.mean(accuracy))\n",
    "print('Sensitivity:', np.mean(sensitivity))\n",
    "print('Specificity:', np.mean(specificity))\n",
    "print('G-mean:', np.mean(gmean))\n",
    "print('F1 Score:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60e5f8",
   "metadata": {},
   "source": [
    "<b> TASK 4 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06720536",
   "metadata": {},
   "source": [
    "The sequential feature selection strategy should be used while running the model for both Logistic Regression and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a58c20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********LOGISTIC REGRESSION*****************************\n",
      "Accuracy: 0.8350574712643679\n",
      "Sensitivity: 0.801788073038073\n",
      "Specificity: 0.8628227431323406\n",
      "G-mean: 0.8270831191707373\n",
      "F1 Score: 0.8176392827602506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "accuracy = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "gmean = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10)\n",
    "    rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = rfe.predict(X_test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    specificity.append(confusion_matrix(y_test, y_pred)[0,0]/(confusion_matrix(y_test, y_pred)[0,0] + confusion_matrix(y_test, y_pred)[0,1]))\n",
    "    gmean.append(np.sqrt(recall_score(y_test, y_pred) * specificity[-1]))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "print('***********LOGISTIC REGRESSION*****************************')\n",
    "print('Accuracy:', np.mean(accuracy))\n",
    "print('Sensitivity:', np.mean(sensitivity))\n",
    "print('Specificity:', np.mean(specificity))\n",
    "print('G-mean:', np.mean(gmean))\n",
    "print('F1 Score:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20e9a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Support Verctor Machine****************\n",
      "Accuracy: 0.8282758620689655\n",
      "Sensitivity: 0.7738597513597514\n",
      "Specificity: 0.877093898963094\n",
      "G-mean: 0.8192886116614281\n",
      "F1 Score: 0.8027680897877252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "accuracy = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "gmean = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    rfe = RFE(estimator=SVC(kernel='linear'), n_features_to_select=10)\n",
    "    rfe = rfe.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = rfe.predict(X_test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    sensitivity.append(recall_score(y_test, y_pred))\n",
    "    specificity.append(confusion_matrix(y_test, y_pred)[0,0]/(confusion_matrix(y_test, y_pred)[0,0] + confusion_matrix(y_test, y_pred)[0,1]))\n",
    "    gmean.append(np.sqrt(recall_score(y_test, y_pred) * specificity[-1]))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "print('***************Support Verctor Machine****************')\n",
    "print('Accuracy:', np.mean(accuracy))\n",
    "print('Sensitivity:', np.mean(sensitivity))\n",
    "print('Specificity:', np.mean(specificity))\n",
    "print('G-mean:', np.mean(gmean))\n",
    "print('F1 Score:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c226eee",
   "metadata": {},
   "source": [
    "<b> TASK 5 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65af83",
   "metadata": {},
   "source": [
    "1. Logistic Regression outperformed SVM in Part 3 and 4.\n",
    "2. With feature selection of the ten most relevant characteristics, SVM and Logistic Regression in part 4 perform significantly better than in part 3 across all performance criteria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
